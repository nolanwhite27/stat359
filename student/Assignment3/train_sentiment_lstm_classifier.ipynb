{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfeb8c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import gensim.downloader as api\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# device (cuda > mps > cpu)\n",
    "device = \"mps\"\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99ea67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"financial_phrasebank\",\n",
    "    \"sentences_50agree\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "df = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74a59ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: 3501 618 727\n"
     ]
    }
   ],
   "source": [
    "train_val_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.15,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=0.15,\n",
    "    stratify=train_val_df[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Sizes:\", len(train_df), len(val_df), len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7192b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText vectors...\n",
      "Loaded FastText. Dim: 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading FastText vectors...\")\n",
    "ft = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "print(\"Loaded FastText. Dim:\", ft.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb81e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 32\n",
    "TOKEN_RE = re.compile(r\"[A-Za-z]+(?:'[A-Za-z]+)?|\\d+(?:\\.\\d+)?\")\n",
    "\n",
    "def tokenize(text: str):\n",
    "    return TOKEN_RE.findall(text.lower())\n",
    "\n",
    "def sentence_to_matrix(sentence: str, ft, max_len=MAX_LEN):\n",
    "    \n",
    "    tokens = tokenize(sentence)[:max_len]\n",
    "    dim = ft.vector_size\n",
    "    mat = np.zeros((max_len, dim), dtype=np.float32)\n",
    "\n",
    "    for i, tok in enumerate(tokens):\n",
    "        try:\n",
    "            mat[i] = ft[tok]\n",
    "        except KeyError:\n",
    "            pass  # leave as zeros\n",
    "    return mat\n",
    "\n",
    "def build_sequence_features(df, ft, max_len=MAX_LEN):\n",
    "    X = np.stack([sentence_to_matrix(s, ft, max_len=max_len) for s in df[\"sentence\"].tolist()])\n",
    "    y = df[\"label\"].to_numpy(dtype=np.int64)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43d96e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (3501, 32, 300) y_train: (3501,)\n",
      "X_val:   (618, 32, 300) y_val:   (618,)\n",
      "X_test:  (727, 32, 300) y_test:  (727,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = build_sequence_features(train_df, ft)\n",
    "X_val, y_val     = build_sequence_features(val_df, ft)\n",
    "X_test, y_test   = build_sequence_features(test_df, ft)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
    "print(\"X_test: \", X_test.shape,  \"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c5f4018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train counts: [ 436 2080  985]\n",
      "Class weights: tensor([2.6766, 0.5611, 1.1848])\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "counts = np.bincount(y_train, minlength=num_classes)\n",
    "N = counts.sum()\n",
    "\n",
    "class_weights = N / (num_classes * counts)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "print(\"Train counts:\", counts)\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6af87364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)  # (N, 32, 300) float32\n",
    "        self.y = torch.from_numpy(y)  # (N,) int64\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_loader = DataLoader(SeqDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(SeqDataset(X_val, y_val),     batch_size=256, shuffle=False)\n",
    "test_loader  = DataLoader(SeqDataset(X_test, y_test),   batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "739aeaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=300, hidden_dim=128, num_layers=1, dropout=0.2, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,  # input: (B, 32, 300)\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 32, 300)\n",
    "        _, (h_n, _) = self.lstm(x)  # h_n: (num_layers, B, hidden_dim)\n",
    "        h_last = h_n[-1]            # (B, hidden_dim)\n",
    "        h_last = self.dropout(h_last)\n",
    "        return self.fc(h_last)      # logits: (B, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a69d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (lstm): LSTM(300, 128, batch_first=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(input_dim=300, hidden_dim=128, num_layers=1, dropout=0.2, num_classes=3).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e8c0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_y = [], []\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_y.append(y.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_y = np.concatenate(all_y)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    acc = (all_preds == all_y).mean()\n",
    "    macro_f1 = f1_score(all_y, all_preds, average=\"macro\")\n",
    "    return avg_loss, acc, macro_f1\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_y = [], []\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_y.append(y.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_y = np.concatenate(all_y)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    acc = (all_preds == all_y).mean()\n",
    "    macro_f1 = f1_score(all_y, all_preds, average=\"macro\")\n",
    "    return avg_loss, acc, macro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ec6a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    num_epochs=30,\n",
    "    save_path=\"best_lstm_fasttext.pt\",\n",
    "):\n",
    "    best_val_f1 = -1.0\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_macro_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_macro_f1\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion, device\n",
    "        )\n",
    "        val_loss, val_acc, val_f1 = evaluate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"train_macro_f1\"].append(train_f1)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_macro_f1\"].append(val_f1)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d} | \"\n",
    "            f\"train loss {train_loss:.4f} acc {train_acc:.4f} f1 {train_f1:.4f} | \"\n",
    "            f\"val loss {val_loss:.4f} acc {val_acc:.4f} f1 {val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Saved new best model (val macro-F1 = {best_val_f1:.4f}) -> {save_path}\")\n",
    "\n",
    "    return best_val_f1, pd.DataFrame(history)\n",
    "\n",
    "def plot_metric(history_df, train_col, val_col, ylabel, filename):\n",
    "    plt.figure()\n",
    "    plt.plot(history_df[\"epoch\"], history_df[train_col], label=\"train\")\n",
    "    plt.plot(history_df[\"epoch\"], history_df[val_col], label=\"val\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(f\"{ylabel} vs Epochs\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=200)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6cf31ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 1.0939 acc 0.4841 f1 0.3609 | val loss 1.0866 acc 0.4871 f1 0.3424\n",
      "  ✅ Saved new best model (val macro-F1 = 0.3424) -> best_lstm_fasttext.pt\n",
      "Epoch 02 | train loss 1.0421 acc 0.5818 f1 0.4049 | val loss 1.0320 acc 0.5922 f1 0.3804\n",
      "  ✅ Saved new best model (val macro-F1 = 0.3804) -> best_lstm_fasttext.pt\n",
      "Epoch 03 | train loss 0.9925 acc 0.6033 f1 0.4253 | val loss 0.9871 acc 0.6327 f1 0.4295\n",
      "  ✅ Saved new best model (val macro-F1 = 0.4295) -> best_lstm_fasttext.pt\n",
      "Epoch 04 | train loss 0.9242 acc 0.6010 f1 0.4295 | val loss 0.9439 acc 0.4676 f1 0.3529\n",
      "Epoch 05 | train loss 0.8893 acc 0.6215 f1 0.4500 | val loss 0.8652 acc 0.6019 f1 0.4317\n",
      "  ✅ Saved new best model (val macro-F1 = 0.4317) -> best_lstm_fasttext.pt\n",
      "Epoch 06 | train loss 0.8403 acc 0.6430 f1 0.4857 | val loss 0.8914 acc 0.5485 f1 0.4104\n",
      "Epoch 07 | train loss 0.8264 acc 0.6404 f1 0.4973 | val loss 0.9413 acc 0.4515 f1 0.3841\n",
      "Epoch 08 | train loss 0.8421 acc 0.6372 f1 0.5070 | val loss 0.8551 acc 0.6181 f1 0.5072\n",
      "  ✅ Saved new best model (val macro-F1 = 0.5072) -> best_lstm_fasttext.pt\n",
      "Epoch 09 | train loss 0.8186 acc 0.6495 f1 0.5197 | val loss 0.8060 acc 0.6764 f1 0.5556\n",
      "  ✅ Saved new best model (val macro-F1 = 0.5556) -> best_lstm_fasttext.pt\n",
      "Epoch 10 | train loss 0.7749 acc 0.6595 f1 0.5595 | val loss 0.8101 acc 0.6214 f1 0.5674\n",
      "  ✅ Saved new best model (val macro-F1 = 0.5674) -> best_lstm_fasttext.pt\n",
      "Epoch 11 | train loss 0.7544 acc 0.6624 f1 0.5851 | val loss 0.8070 acc 0.6845 f1 0.5688\n",
      "  ✅ Saved new best model (val macro-F1 = 0.5688) -> best_lstm_fasttext.pt\n",
      "Epoch 12 | train loss 0.7094 acc 0.6730 f1 0.6165 | val loss 0.7829 acc 0.6343 f1 0.5860\n",
      "  ✅ Saved new best model (val macro-F1 = 0.5860) -> best_lstm_fasttext.pt\n",
      "Epoch 13 | train loss 0.7082 acc 0.6632 f1 0.6354 | val loss 0.7995 acc 0.6650 f1 0.5967\n",
      "  ✅ Saved new best model (val macro-F1 = 0.5967) -> best_lstm_fasttext.pt\n",
      "Epoch 14 | train loss 0.6980 acc 0.6430 f1 0.6274 | val loss 0.7551 acc 0.5696 f1 0.5782\n",
      "Epoch 15 | train loss 0.6418 acc 0.6944 f1 0.6761 | val loss 0.7248 acc 0.6667 f1 0.6217\n",
      "  ✅ Saved new best model (val macro-F1 = 0.6217) -> best_lstm_fasttext.pt\n",
      "Epoch 16 | train loss 0.6240 acc 0.7121 f1 0.6902 | val loss 0.7292 acc 0.6748 f1 0.6470\n",
      "  ✅ Saved new best model (val macro-F1 = 0.6470) -> best_lstm_fasttext.pt\n",
      "Epoch 17 | train loss 0.6156 acc 0.6884 f1 0.6849 | val loss 0.7804 acc 0.6472 f1 0.6061\n",
      "Epoch 18 | train loss 0.6033 acc 0.7084 f1 0.6986 | val loss 0.7475 acc 0.6715 f1 0.6490\n",
      "  ✅ Saved new best model (val macro-F1 = 0.6490) -> best_lstm_fasttext.pt\n",
      "Epoch 19 | train loss 0.5636 acc 0.7232 f1 0.7244 | val loss 0.7679 acc 0.5631 f1 0.5852\n",
      "Epoch 20 | train loss 0.5572 acc 0.7424 f1 0.7303 | val loss 0.7797 acc 0.6602 f1 0.6405\n",
      "Epoch 21 | train loss 0.5304 acc 0.7675 f1 0.7516 | val loss 0.7011 acc 0.6780 f1 0.6597\n",
      "  ✅ Saved new best model (val macro-F1 = 0.6597) -> best_lstm_fasttext.pt\n",
      "Epoch 22 | train loss 0.5004 acc 0.7695 f1 0.7598 | val loss 0.7568 acc 0.6748 f1 0.6599\n",
      "  ✅ Saved new best model (val macro-F1 = 0.6599) -> best_lstm_fasttext.pt\n",
      "Epoch 23 | train loss 0.5536 acc 0.7389 f1 0.7200 | val loss 0.7660 acc 0.5146 f1 0.5318\n",
      "Epoch 24 | train loss 0.5115 acc 0.7484 f1 0.7440 | val loss 0.6869 acc 0.6909 f1 0.6391\n",
      "Epoch 25 | train loss 0.4622 acc 0.7906 f1 0.7766 | val loss 0.6558 acc 0.7055 f1 0.6712\n",
      "  ✅ Saved new best model (val macro-F1 = 0.6712) -> best_lstm_fasttext.pt\n",
      "Epoch 26 | train loss 0.4448 acc 0.7938 f1 0.7811 | val loss 0.6695 acc 0.7395 f1 0.7116\n",
      "  ✅ Saved new best model (val macro-F1 = 0.7116) -> best_lstm_fasttext.pt\n",
      "Epoch 27 | train loss 0.4527 acc 0.8015 f1 0.7896 | val loss 0.7519 acc 0.7071 f1 0.6931\n",
      "Epoch 28 | train loss 0.4213 acc 0.7992 f1 0.7880 | val loss 0.7462 acc 0.7346 f1 0.7056\n",
      "Epoch 29 | train loss 0.4205 acc 0.8026 f1 0.7951 | val loss 0.7251 acc 0.6926 f1 0.6705\n",
      "Epoch 30 | train loss 0.4009 acc 0.8183 f1 0.8098 | val loss 0.7187 acc 0.7492 f1 0.7106\n"
     ]
    }
   ],
   "source": [
    "best_val_f1, history_df = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    num_epochs=30,  # required\n",
    "    save_path=\"best_lstm_fasttext.pt\",\n",
    ")\n",
    "\n",
    "history_df.to_csv(\"lstm_fasttext_history.csv\", index=False)\n",
    "\n",
    "plot_metric(history_df, \"train_loss\", \"val_loss\", \"Loss\", \"lstm_loss_vs_epochs.png\")\n",
    "plot_metric(history_df, \"train_acc\", \"val_acc\", \"Accuracy\", \"lstm_accuracy_vs_epochs.png\")\n",
    "plot_metric(history_df, \"train_macro_f1\", \"val_macro_f1\", \"Macro F1\", \"lstm_macro_f1_vs_epochs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "770c9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test macro-F1: 0.7246091657490815\n",
      "LSTM passes 0.70 threshold.\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_test_macro_f1(model_class, model_kwargs, model_path, test_loader, device):\n",
    "    model = model_class(**model_kwargs).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_y = [], []\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        logits = model(X)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_y.append(y.numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_y = np.concatenate(all_y)\n",
    "    return f1_score(all_y, all_preds, average=\"macro\")\n",
    "\n",
    "model_kwargs = dict(input_dim=300, hidden_dim=128, num_layers=1, dropout=0.2, num_classes=3)\n",
    "\n",
    "test_macro_f1 = evaluate_test_macro_f1(\n",
    "    model_class=LSTMClassifier,\n",
    "    model_kwargs=model_kwargs,\n",
    "    model_path=\"best_lstm_fasttext.pt\",\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Test macro-F1:\", test_macro_f1)\n",
    "if test_macro_f1 > 0.7:\n",
    "    print(\"LSTM passes 0.70 threshold.\")\n",
    "else: \n",
    "    print(\"LSTM does not pass 0.70 threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6f08f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_preds_and_labels(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds_all, y_all = [], []\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        logits = model(X)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        preds_all.append(preds)\n",
    "        y_all.append(y.numpy())\n",
    "    return np.concatenate(preds_all), np.concatenate(y_all)\n",
    "\n",
    "def save_confusion_matrix(model_class, model_kwargs, model_path, test_loader, device,\n",
    "                          filename=\"lstm_confusion_matrix.png\"):\n",
    "    model = model_class(**model_kwargs).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    preds, y = get_preds_and_labels(model, test_loader, device)\n",
    "\n",
    "    cm = confusion_matrix(y, preds, labels=[0, 1, 2])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"neg\", \"neu\", \"pos\"])\n",
    "\n",
    "    plt.figure()\n",
    "    disp.plot(values_format=\"d\")\n",
    "    plt.title(\"LSTM Confusion Matrix (Test)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=200)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eebdd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_confusion_matrix(\n",
    "    model_class=LSTMClassifier,\n",
    "    model_kwargs=model_kwargs,\n",
    "    model_path=\"best_lstm_fasttext.pt\",\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    filename=\"lstm_confusion_matrix.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat359-su25-py3.12 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
